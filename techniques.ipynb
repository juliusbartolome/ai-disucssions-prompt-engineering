{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "API_KEY = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "MODEL = os.environ.get(\"HUGGINGFACE_MODEL\")\n",
    "\n",
    "if not API_KEY or not MODEL:\n",
    "    raise Exception(\"Environment variables HUGGINGFACE_API_KEY and HUGGINGFACE_MODEL must be set.\")\n",
    "\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL}\"\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "def query(prompt):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json={\n",
    "\t\t\"inputs\": prompt,\n",
    "\t\t\"parameters\": {\n",
    "      # \"return_full_text\": False\n",
    "    }\n",
    "  })\n",
    "\tjson = response.json()\n",
    "\treturn json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me something about basketball that I donâ€™t know.\n",
      "\n",
      "Basketball is a sport that was invented in 1891 by Dr. James Naismith, a Canadian physical education instructor. The game was originally designed as a way to keep athletes active during the winter months when outdoor sports were not possible. The objective of the game is to score points by shooting a ball through a hoop mounted 10 feet above the ground. The team with the most points at the end of the game wins\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me something about basketball\"\n",
    "\n",
    "output = query(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree of Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Reasoning Tool-use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Prompt Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active-Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program-Aided Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Chain-of-Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prompt_engineering]",
   "language": "python",
   "name": "conda-env-prompt_engineering-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
